{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_main_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTvSVbd7Ax_c",
        "outputId": "acc39f13-28ff-4e53-c057-aecac26008fe"
      },
      "source": [
        "# import libraries\n",
        "!pip3 install box2d-py\n",
        "\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# import python files here ... \n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXSt2ozZBFcG"
      },
      "source": [
        "# pytorch device (we are using cpu)\n",
        "device = torch.device('cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8-7Gf_ABXvL"
      },
      "source": [
        "### training setup \n",
        "\n",
        "# initialize enviornment \n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "max_episode_steps = 1000 # this number if a given from the source code\n",
        "\n",
        "# these enviornment attributes will be passed into training algorithm \n",
        "state_dim = env.observation_space.shape[0] \n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# PPO algorithm hyerparameters\n",
        "lr_actor = 0.0003\n",
        "lr_critic = 0.001\n",
        "\n",
        "udpate_frequency = max_episode_steps * 4  # update policy every (4) timestep\n",
        "k_epochs = 40                             # K num. epochs\n",
        "eps_clip = 0.2                            # clipping parameter epsilon\n",
        "gamma = 0.99                              # discount \n",
        "\n",
        "# training hyperparameters\n",
        "max_training_steps = 10000 # arbitrarily set 10k training iterations\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os6tEWbrBX0j"
      },
      "source": [
        "### training\n",
        "\n",
        "# (hi steven, the training loop/function will go here)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4MHpJIVBX3G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rjhxcYhBT1a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}